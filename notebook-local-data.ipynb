{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, to_timestamp, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld, DoubleType as Dbl, StringType as Str\n",
    "from pyspark.sql.types import IntegerType as Int, LongType as Long, DateType as Date, TimestampType as Tst\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['Credentials']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['Credentials']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:2.7.0') \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data = \"s3n://udacity-dend/\"\n",
    "input_data = './data/'\n",
    "output_data = './outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = input_data + 'song_data/*/*/*/*.json'\n",
    "#log_data = input_data + 'log_data/*/*/*.json'\n",
    "log_data = input_data + 'log_data/*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = spark.read.json(song_data)\n",
    "df_2 = spark.read.json(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8056"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist_id='ARDR4AC1187FB371A1', artist_latitude=None, artist_location='', artist_longitude=None, artist_name='Montserrat Caball√©;Placido Domingo;Vicente Sardinero;Judith Blegen;Sherrill Milnes;Georg Solti', duration=511.16363, num_songs=1, song_id='SOBAYLL12A8C138AF9', title='Sono andati? Fingevo di dormire', year=0),\n",
       " Row(artist_id='AREBBGV1187FB523D2', artist_latitude=None, artist_location='Houston, TX', artist_longitude=None, artist_name=\"Mike Jones (Featuring CJ_ Mello & Lil' Bran)\", duration=173.66159, num_songs=1, song_id='SOOLYAZ12A6701F4A6', title='Laws Patrolling (Album Version)', year=0),\n",
       " Row(artist_id='ARMAC4T1187FB3FA4C', artist_latitude=40.82624, artist_location='Morris Plains, NJ', artist_longitude=-74.47995, artist_name='The Dillinger Escape Plan', duration=207.77751, num_songs=1, song_id='SOBBUGU12A8C13E95D', title='Setting Fire to Sleeping Giants', year=2004),\n",
       " Row(artist_id='ARPBNLO1187FB3D52F', artist_latitude=40.71455, artist_location='New York, NY', artist_longitude=-74.00712, artist_name='Tiny Tim', duration=43.36281, num_songs=1, song_id='SOAOIBZ12AB01815BE', title='I Hold Your Hand In Mine [Live At Royal Albert Hall]', year=2000),\n",
       " Row(artist_id='ARDNS031187B9924F0', artist_latitude=32.67828, artist_location='Georgia', artist_longitude=-83.22295, artist_name='Tim Wilson', duration=186.48771, num_songs=1, song_id='SONYPOM12A8C13B2D7', title='I Think My Wife Is Running Around On Me (Taco Hell)', year=2005),\n",
       " Row(artist_id='ARNF6401187FB57032', artist_latitude=40.79086, artist_location='New York, NY [Manhattan]', artist_longitude=-73.96644, artist_name='Sophie B. Hawkins', duration=305.162, num_songs=1, song_id='SONWXQJ12A8C134D94', title='The Ballad Of Sleeping Beauty', year=1994),\n",
       " Row(artist_id='ARLTWXK1187FB5A3F8', artist_latitude=32.74863, artist_location='Fort Worth, TX', artist_longitude=-97.32925, artist_name='King Curtis', duration=326.00771, num_songs=1, song_id='SODREIN12A58A7F2E5', title='A Whiter Shade Of Pale (Live @ Fillmore West)', year=0),\n",
       " Row(artist_id='ARPFHN61187FB575F6', artist_latitude=41.88415, artist_location='Chicago, IL', artist_longitude=-87.63241, artist_name='Lupe Fiasco', duration=279.97995, num_songs=1, song_id='SOWQTQZ12A58A7B63E', title='Streets On Fire (Explicit Album Version)', year=0),\n",
       " Row(artist_id='ARI2JSK1187FB496EF', artist_latitude=51.50632, artist_location='London, England', artist_longitude=-0.12714, artist_name='Nick Ingman;Gavyn Wright', duration=111.62077, num_songs=1, song_id='SODUJBS12A8C132150', title='Wessex Loses a Bride', year=0),\n",
       " Row(artist_id='AROUOZZ1187B9ABE51', artist_latitude=40.79195, artist_location='New York, NY [Spanish Harlem]', artist_longitude=-73.94512, artist_name='Willie Bobo', duration=168.25424, num_songs=1, song_id='SOBZBAZ12A6D4F8742', title='Spanish Grease', year=1997)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(artist='Harmonia', auth='Logged In', firstName='Ryan', gender='M', itemInSession=0, lastName='Smith', length=655.77751, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='Sehr kosmisch', status=200, ts=1542241826796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26'),\n",
       " Row(artist='The Prodigy', auth='Logged In', firstName='Ryan', gender='M', itemInSession=1, lastName='Smith', length=260.07465, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='The Big Gundown', status=200, ts=1542242481796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26'),\n",
       " Row(artist='Train', auth='Logged In', firstName='Ryan', gender='M', itemInSession=2, lastName='Smith', length=205.45261, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='Marry Me', status=200, ts=1542242741796, userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26'),\n",
       " Row(artist=None, auth='Logged In', firstName='Wyatt', gender='M', itemInSession=0, lastName='Scott', length=None, level='free', location='Eureka-Arcata-Fortuna, CA', method='GET', page='Home', registration=1540872073796.0, sessionId=563, song=None, status=200, ts=1542247071796, userAgent='Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko', userId='9'),\n",
       " Row(artist=None, auth='Logged In', firstName='Austin', gender='M', itemInSession=0, lastName='Rosales', length=None, level='free', location='New York-Newark-Jersey City, NY-NJ-PA', method='GET', page='Home', registration=1541059521796.0, sessionId=521, song=None, status=200, ts=1542252577796, userAgent='Mozilla/5.0 (Windows NT 6.1; rv:31.0) Gecko/20100101 Firefox/31.0', userId='12'),\n",
       " Row(artist='Sony Wonder', auth='Logged In', firstName='Samuel', gender='M', itemInSession=0, lastName='Gonzalez', length=218.06975, level='free', location='Houston-The Woodlands-Sugar Land, TX', method='PUT', page='NextSong', registration=1540492941796.0, sessionId=597, song='Blackbird', status=200, ts=1542253449796, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.77.4 (KHTML, like Gecko) Version/7.0.5 Safari/537.77.4\"', userId='61'),\n",
       " Row(artist=None, auth='Logged In', firstName='Samuel', gender='M', itemInSession=1, lastName='Gonzalez', length=None, level='free', location='Houston-The Woodlands-Sugar Land, TX', method='GET', page='About', registration=1540492941796.0, sessionId=597, song=None, status=200, ts=1542253460796, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.77.4 (KHTML, like Gecko) Version/7.0.5 Safari/537.77.4\"', userId='61'),\n",
       " Row(artist=None, auth='Logged Out', firstName=None, gender=None, itemInSession=0, lastName=None, length=None, level='paid', location=None, method='PUT', page='Login', registration=None, sessionId=602, song=None, status=307, ts=1542260074796, userAgent=None, userId=''),\n",
       " Row(artist=None, auth='Logged In', firstName='Tegan', gender='F', itemInSession=1, lastName='Levine', length=None, level='paid', location='Portland-South Portland, ME', method='GET', page='Home', registration=1540794356796.0, sessionId=602, song=None, status=200, ts=1542260277796, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId='80'),\n",
       " Row(artist='Van Halen', auth='Logged In', firstName='Tegan', gender='F', itemInSession=2, lastName='Levine', length=289.38404, level='paid', location='Portland-South Portland, ME', method='PUT', page='NextSong', registration=1540794356796.0, sessionId=602, song='Best Of Both Worlds (Remastered Album Version)', status=200, ts=1542260935796, userAgent='\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"', userId='80')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_song_data(spark, input_data, output_data):\n",
    "    '''\n",
    "    load song data in json format from S3 bucket and process these data by extracting \n",
    "    songs table and artists table, and save these tables back to S3 bucket\n",
    "    \n",
    "    :param spark: spark session\n",
    "    :param input_data: data location for input data\n",
    "    :param output_data: data location for output data\n",
    "    :return: no return value\n",
    "    '''\n",
    "    # get filepath to song data file\n",
    "    song_data = input_data + 'song_data/*/*/*/*.json'\n",
    "    \n",
    "    # create songs schema\n",
    "    songSchema = R([\n",
    "        Fld('artist_id',Str()),\n",
    "        Fld('artist_latitude',Dbl()),\n",
    "        Fld('artist_location',Str()),\n",
    "        Fld('artist_longitude',Dbl()),\n",
    "        Fld('artist_name',Str()),\n",
    "        Fld('duration',Dbl()),\n",
    "        Fld('num_songs',Int()),\n",
    "        Fld('title',Str()),\n",
    "        Fld('year',Int()),\n",
    "    ])\n",
    "    \n",
    "    # load songs json files from S3\n",
    "    df_songs = spark.read.json(song_data, schema=songSchema)\n",
    "    \n",
    "    # select columns for songs_table\n",
    "    songs_attr = ['title', 'artist_id','year', 'duration']\n",
    "    songs_table = df_songs.select(songs_attr)\\\n",
    "    .dropDuplicates()\\\n",
    "    .withColumn('song_id', monotonically_increasing_id())\n",
    "    \n",
    "    # write songs_table to S3\n",
    "    songs_table.write.partitionBy('year', 'artist_id').parquet(output_data + 'songs/')\n",
    "    \n",
    "    # select artists columns\n",
    "    artists_attr = ['artist_id', 'artist_name', 'artist_location', \n",
    "                   'artist_latitude', 'artist_longitude']\n",
    "    artists_table = df_songs.select(artists_attr)\\\n",
    "    .dropDuplicates()\n",
    "    \n",
    "    artists_table = artists_table\\\n",
    "    .withColumnRenamed('artist_name','name')\\\n",
    "    .withColumnRenamed('artist_location','location')\\\n",
    "    .withColumnRenamed('artist_latitude','latitude')\\\n",
    "    .withColumnRenamed('artist_longitude','longitude')\n",
    "    \n",
    "    # write artists_table to S3\n",
    "    artists_table.write.parquet(output_data + 'artists/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_song_data(spark, input_data, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_log_data(spark, input_data, output_data):\n",
    "    '''\n",
    "    load log data in json format from S3 bucket and process these data by extracting \n",
    "    users table, time table and songplays table, and save these tables back to S3 bucket\n",
    "    \n",
    "    :param spark: spark session\n",
    "    :param input_data: data location for input data\n",
    "    :param output_data: data location for output data\n",
    "    :return: no return value\n",
    "    '''\n",
    "    \n",
    "    # get filepath to log data file\n",
    "#     log_data = input_data + 'log_data/*/*/*.json'\n",
    "    log_data = input_data + 'log_data/*.json'\n",
    "    \n",
    "    logdataSchema = R([\n",
    "        Fld('artist', Str()),\n",
    "        Fld('auth', Str()),\n",
    "        Fld('firstName', Str()),\n",
    "        Fld('gender', Str()),\n",
    "        Fld('itemInSession', Long()),\n",
    "        Fld('lastName', Str()),\n",
    "        Fld('length', Dbl()),\n",
    "        Fld('level', Str()),\n",
    "        Fld('location', Str()),\n",
    "        Fld('method', Str()),\n",
    "        Fld('page', Str()),\n",
    "        Fld('registration', Dbl()),\n",
    "        Fld('sessionId', Long()),\n",
    "        Fld('song', Str()),\n",
    "        Fld('status', Long()),\n",
    "        Fld('ts', Long()),\n",
    "        Fld('userAgent', Str()),\n",
    "        Fld('userId', Str()),\n",
    "    ])\n",
    "\n",
    "    # load json files from S3\n",
    "    df_log = spark.read.json(log_data, schema=logdataSchema)\n",
    "    df_log = df_log.filter(df_log.page == 'NextSong')\n",
    "    \n",
    "    # select users columns\n",
    "    users_attr = ['userId', 'firstName', 'lastName', 'gender', 'level']\n",
    "    users_table = df_log.select(users_attr)\\\n",
    "    .dropDuplicates()\n",
    "    \n",
    "    users_table = users_table\\\n",
    "    .withColumnRenamed('userId','user_id')\\\n",
    "    .withColumnRenamed('firstName','first_name')\\\n",
    "    .withColumnRenamed('lastName','last_name')\n",
    "    \n",
    "    # write users table to S3\n",
    "    users_table.write.parquet(output_data + 'users/')\n",
    "    \n",
    "    # create time table\n",
    "    tsFormat = 'yyyy-MM-dd HH:MM:ss z'\n",
    "    time_table = df_log.withColumn('ts', \n",
    "                                   to_timestamp(date_format((df_log.ts/1000)\\\n",
    "                                                            .cast(dataType=Tst()), \n",
    "                                                            tsFormat), tsFormat))\n",
    "\n",
    "    time_table = time_table.select(col('ts').alias('start_time'),\n",
    "                                   hour(col('ts')).alias('hour'),\n",
    "                                   dayofmonth(col('ts')).alias('day'), \n",
    "                                   weekofyear(col('ts')).alias('week'), \n",
    "                                   month(col('ts')).alias('month'),\n",
    "                                   year(col('ts')).alias('year'))\n",
    "\n",
    "    # write time table to S3\n",
    "    time_table.write.partitionBy('year', 'month').parquet(output_data + 'time/')\n",
    "\n",
    "    # load songs and artist tables from previous handling\n",
    "    df_songs = spark.read.parquet(output_data + 'songs/*/*/*')\n",
    "    df_artists = spark.read.parquet(output_data + 'artists/*')\n",
    "    df_artists = df_artists.drop('location')\n",
    "\n",
    "    # create songs_logs table\n",
    "    songs_logs = df_log.join(df_songs, (df_log.song == df_songs.title))\n",
    "    \n",
    "    # create artists_songs_logs table\n",
    "#     artists_songs_logs = songs_logs.join(df_artists, \n",
    "#                                          (songs_logs.artist == df_artists.name))\n",
    "#     artists_songs_logs = artists_songs_logs.withColumn('ts', \n",
    "#                                                        to_timestamp(date_format((artists_songs_logs.ts/1000)\\\n",
    "#                                                                                 .cast(dataType=TimestampType()),\n",
    "#                                                                                 tsFormat), tsFormat))\n",
    "\n",
    "    # create artists_songs_logs table\n",
    "    artists_songs_logs = songs_logs.join(df_artists, \n",
    "                                         (songs_logs.artist == df_artists.name))\n",
    "    \n",
    "    artists_songs_logs = artists_songs_logs\\\n",
    "    .withColumn('ts', \n",
    "                to_timestamp(date_format((artists_songs_logs.ts/1000)\\\n",
    "                                         .cast(dataType=Tst()),tsFormat), tsFormat))\n",
    "    \n",
    "    # create songplays table\n",
    "    songplays = artists_songs_logs.join(\n",
    "        time_table,\n",
    "        artists_songs_logs.ts == time_table.start_time, 'left')\n",
    "    \n",
    "    songplays_attr = ['start_time', 'userId', 'level', 'song_id', 'artist_id',\n",
    "                      'sessionId', 'location', 'userAgent', 'year', 'month']\n",
    "    \n",
    "    songplays_table = songplays.select(songplays_attr)\\\n",
    "    .dropDuplicates()\n",
    "    \n",
    "    songplays_table = songplays_table\\\n",
    "    .withColumnRenamed('userId','user_id')\\\n",
    "    .withColumnRenamed('sessionId','session_id')\\\n",
    "    .withColumnRenamed('userAgent','user_agent')\\\n",
    "    .repartition('year', 'month')\n",
    "\n",
    "    # write songplays table to S3\n",
    "    songplays_table.write.partitionBy('year', 'month').parquet(output_data + 'songplays/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_log_data(spark, input_data, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
